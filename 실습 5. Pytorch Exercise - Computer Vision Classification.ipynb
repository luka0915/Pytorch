{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM21rOdDjgiSmhW0UY18mf8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","import sklearn\n","from sklearn.metrics import classification_report\n","from tqdm import tqdm"],"metadata":{"id":"YbKdfQnrSM9S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# seed 고정 (rand 함수 실행시 같은 결과 나올 수 있도록)\n","def seed_everything(seed: int):\n","    import random, os\n","    import numpy as np\n","    import torch\n","\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(42)"],"metadata":{"id":"E0re-LoUfQwo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","# 0. Convolutional Layer\n","\n"],"metadata":{"id":"ODbpxOTpSMfn"}},{"cell_type":"code","source":["# Define the convolutional layer\n","conv = nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3, stride=1, padding='same')\n","\n","for p in conv.parameters():\n","    print(p)"],"metadata":{"id":"AKFO-0cYSZK5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the input tensor\n","input = torch.randn(10, 3, 7, 7) # Batch_size, Kernel_size, Height, Weight\n","\n","# Apply the convolution\n","output = conv(input)\n","\n","# Print the output shape\n","print(output.shape)"],"metadata":{"id":"LXhbwFmQXScI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. CNN"],"metadata":{"id":"Wpy9H1mISZqI"}},{"cell_type":"markdown","source":["### Dataset Preparation"],"metadata":{"id":"30w3v03hShKK"}},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(\n","    datasets.FashionMNIST(\"data\", train=True, download=True, transform=transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,))\n","    ])),\n","    batch_size=64, shuffle=True\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.FashionMNIST(\"data\", train=False, download=True, transform=transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,))\n","    ])),\n","    batch_size=64, shuffle=True\n",")\n"],"metadata":{"id":"9YgHIYtbSgHz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### CNN 선언"],"metadata":{"id":"Omot8EcrSp3S"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fSbIydNpXvCG"},"outputs":[],"source":["# 모델 정의\n","class FashionMNISTModel(nn.Module):\n","    def __init__(self):\n","        super(FashionMNISTModel, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n","        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.max_pool2d(x, 2)\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2)\n","        x = x.view(-1, 64 * 5 * 5)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)\n","\n","model = FashionMNISTModel()"]},{"cell_type":"code","source":["# Loss, Optimizer 선언\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"metadata":{"id":"nL6QPQy3X2PM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training Loop\n","model.train()\n","\n","for epoch in tqdm(range(5)):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.view(-1, 1, 28, 28)\n","        labels = labels\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i + 1) % 100 == 0:\n","            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n","                epoch + 1, 5, i + 1, len(train_loader), loss.item()))"],"metadata":{"id":"RUFrXroehUIU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GPU 지정\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","print(model.to(device))\n","next(model.parameters()).device # model parameter 위치 확인 (cuda or cpu)"],"metadata":{"id":"QLJfteQnS3ra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loss, Optimizer 재 선언\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"metadata":{"id":"pXk_r3YnkMHA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 모델 학습"],"metadata":{"id":"nC1EPPYa1eRY"}},{"cell_type":"code","source":["# Training Loop using GPU\n","for epoch in tqdm(range(5)):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.view(-1, 1, 28, 28).to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        # if (i + 1) % 100 == 0:\n","        #     print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n","        #         epoch + 1, 5, i + 1, len(train_loader), loss.item()))"],"metadata":{"id":"HfAU0TG7X3ZP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 모델 평가"],"metadata":{"id":"MpYlN4fY1cOI"}},{"cell_type":"code","source":["model.eval()\n","\n","y_pred, y_true = torch.zeros([64]).to(device), torch.zeros([64]).to(device)\n","total, correct = 0, 0\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.view(-1, 1, 28, 28).to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        if (predicted.shape[0]!=64):\n","            predicted = torch.cat([predicted, torch.zeros(64-predicted.shape[0]).to(device)])\n","            labels = torch.cat([labels, torch.zeros(64-labels.shape[0]).to(device)])\n","\n","        y_pred = torch.cat([y_pred, predicted])\n","        y_true = torch.cat([y_true, labels])\n","\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Test Accuracy: {}%'.format((correct / total) * 100))"],"metadata":{"id":"vw9sTJvyX316"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(classification_report(y_true.detach().cpu().numpy(), y_pred.detach().cpu().numpy()))"],"metadata":{"id":"OhX0KVQLsJkP"},"execution_count":null,"outputs":[]}]}